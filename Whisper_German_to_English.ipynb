{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffee141",
   "metadata": {},
   "source": [
    "# OpenAI Whisper German-to-English Translation\n",
    "## Direct Whisper Translate Mode with Auto-Chunking\n",
    "\n",
    "**Objective:**\n",
    "Transcribe German audio and translate directly to English using OpenAI Whisper's translate mode.\n",
    "\n",
    "**Features:**\n",
    "- Whisper API-based translation (no local Whisper)\n",
    "- German speech â†’ English text (direct via translate mode)\n",
    "- Automatic chunking for files exceeding 25MB API limit\n",
    "- Supports: mp3, wav, m4a, flac, ogg, mp4\n",
    "- Secure API key via Colab Secrets\n",
    "- Structured JSON metadata output\n",
    "- Comprehensive error handling and logging\n",
    "\n",
    "**Author:** AI Development Team  \n",
    "**Date:** February 2026  \n",
    "**Environment:** Google Colab  \n",
    "**Status:** Production Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdc670",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies & System Packages\n",
    "\n",
    "Install required Python packages and system libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15780fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Installing Python dependencies...\")\n",
    "packages = [\n",
    "    \"openai>=1.0.0\",      # OpenAI SDK for Whisper API\n",
    "    \"pydub>=0.25.1\",      # Audio file chunking and processing\n",
    "    \"librosa>=0.10.0\"     # Audio duration detection and analysis\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"  Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "print(\"\\nâœ“ Python packages installed successfully!\")\n",
    "\n",
    "# Install system dependencies for audio codec support\n",
    "print(\"\\nInstalling system packages...\")\n",
    "subprocess.check_call([\"apt-get\", \"update\", \"-qq\"], stdout=subprocess.DEVNULL)\n",
    "subprocess.check_call([\"apt-get\", \"install\", \"-y\", \"-qq\", \"ffmpeg\", \"libsndfile1\"], \n",
    "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "print(\"âœ“ System packages installed successfully!\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Setup complete. Ready to configure API and upload audio.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546cd0b",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries & Configure Logging\n",
    "\n",
    "Initialize all required libraries and set up production logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List, Dict, Any\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI, APIConnectionError, RateLimitError, AuthenticationError, APIStatusError\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"All libraries imported successfully.\")\n",
    "logger.info(f\"OpenAI SDK version: {openai.__version__}\")\n",
    "\n",
    "print(\"\\nâœ“ All imports complete and logging configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac6379",
   "metadata": {},
   "source": [
    "## Step 3: Configure API Key & Initialize Client\n",
    "\n",
    "Securely retrieve OpenAI API key and validate connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key() -> str:\n",
    "    \"\"\"\n",
    "    Retrieve OpenAI API key from Colab Secrets or environment variables.\n",
    "    \n",
    "    Returns:\n",
    "        str: Valid OpenAI API key\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If API key not found or empty\n",
    "    \"\"\"\n",
    "    # Try Colab Secrets first (recommended)\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "        if api_key:\n",
    "            logger.info(\"âœ“ API key retrieved from Colab Secrets.\")\n",
    "            return api_key\n",
    "    except (ImportError, Exception):\n",
    "        pass\n",
    "    \n",
    "    # Fallback to environment variable\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if api_key:\n",
    "        logger.info(\"âœ“ API key retrieved from environment variable.\")\n",
    "        return api_key\n",
    "    \n",
    "    raise ValueError(\n",
    "        \"âŒ OpenAI API key not found.\\n\"\n",
    "        \"Please set it via:\\n\"\n",
    "        \"  1. Colab: Click ðŸ”‘ icon â†’ Add OPENAI_API_KEY secret\\n\"\n",
    "        \"  2. OR set environment: os.environ['OPENAI_API_KEY'] = 'sk-...'\"\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_api_key(client: OpenAI) -> bool:\n",
    "    \"\"\"\n",
    "    Validate API key by making a test API call.\n",
    "    \n",
    "    Args:\n",
    "        client (OpenAI): Initialized OpenAI client\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if valid, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Validating API key...\")\n",
    "        # List models to verify authentication\n",
    "        models = client.models.list()\n",
    "        logger.info(\"âœ“ API key validated successfully.\")\n",
    "        return True\n",
    "    except AuthenticationError as e:\n",
    "        logger.error(f\"âŒ Authentication failed: {e}\")\n",
    "        return False\n",
    "    except APIConnectionError as e:\n",
    "        logger.error(f\"âŒ Connection error: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"âŒ Validation error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Initialize client\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Configure API Key\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    api_key = get_api_key()\n",
    "    client = OpenAI(api_key=api_key, timeout=60.0, max_retries=2)\n",
    "    \n",
    "    if validate_api_key(client):\n",
    "        print(\"\\nâœ“ API client initialized and validated successfully!\")\n",
    "    else:\n",
    "        raise ValueError(\"API key validation failed.\")\n",
    "        \n",
    "except ValueError as e:\n",
    "    print(f\"\\n{e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391cbe15",
   "metadata": {},
   "source": [
    "## Step 4: Upload Audio File\n",
    "\n",
    "Upload German audio file from your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85733a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: Upload German Audio File\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSupported formats: mp3, wav, m4a, flac, ogg, mp4\")\n",
    "print(\"Max file size: 500MB (will be auto-chunked if needed)\\n\")\n",
    "\n",
    "uploaded_files = files.upload()\n",
    "\n",
    "if not uploaded_files:\n",
    "    print(\"âŒ No file uploaded. Please upload an audio file.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Get the uploaded filename\n",
    "audio_filename = list(uploaded_files.keys())[0]\n",
    "audio_filepath = os.path.join(\"/tmp\", audio_filename)\n",
    "\n",
    "# Move file to temp directory\n",
    "with open(audio_filepath, 'wb') as f:\n",
    "    f.write(uploaded_files[audio_filename])\n",
    "\n",
    "print(f\"\\nâœ“ File uploaded: {audio_filename}\")\n",
    "print(f\"  Location: {audio_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0546194",
   "metadata": {},
   "source": [
    "## Step 5: Define Helper Functions\n",
    "\n",
    "Core functions for audio validation, chunking, and translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HELPER FUNCTIONS: Audio Validation & Assessment\n",
    "# ============================================================\n",
    "\n",
    "def load_audio(filepath: str) -> Tuple[bool, Optional[str], str]:\n",
    "    \"\"\"\n",
    "    Validate and load audio file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to audio file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, Optional[str], str]: (success, filepath_if_valid, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(filepath):\n",
    "            return False, None, f\"File not found: {filepath}\"\n",
    "        \n",
    "        # Check file size\n",
    "        file_size_mb = os.path.getsize(filepath) / (1024**2)\n",
    "        logger.info(f\"Audio file size: {file_size_mb:.2f} MB\")\n",
    "        \n",
    "        if file_size_mb > 500:\n",
    "            return False, None, f\"File too large: {file_size_mb:.2f}MB (max 500MB)\"\n",
    "        \n",
    "        # Check file extension\n",
    "        supported_formats = ('.mp3', '.wav', '.m4a', '.flac', '.ogg', '.mp4')\n",
    "        if not filepath.lower().endswith(supported_formats):\n",
    "            return False, None, f\"Unsupported format. Supported: {supported_formats}\"\n",
    "        \n",
    "        logger.info(f\"âœ“ Audio file validated: {os.path.basename(filepath)}\")\n",
    "        return True, filepath, \"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, None, f\"Error loading audio: {str(e)}\"\n",
    "\n",
    "\n",
    "def get_audio_duration(filepath: str) -> Tuple[bool, float, str]:\n",
    "    \"\"\"\n",
    "    Detect audio duration using librosa.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to audio file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, float, str]: (success, duration_seconds, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        duration = librosa.get_duration(filename=filepath)\n",
    "        logger.info(f\"Audio duration: {duration:.2f} seconds ({duration/60:.2f} minutes)\")\n",
    "        return True, duration, \"\"\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not detect duration: {str(e)}\")\n",
    "        return False, 0, f\"Duration detection failed: {str(e)}\"\n",
    "\n",
    "\n",
    "def chunk_audio_if_needed(\n",
    "    filepath: str,\n",
    "    chunk_duration_minutes: int = 5,\n",
    "    max_file_size_mb: float = 20.0\n",
    ") -> Tuple[bool, List[str], int, str]:\n",
    "    \"\"\"\n",
    "    Split audio into chunks if it exceeds size/duration thresholds.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to audio file\n",
    "        chunk_duration_minutes (int): Target chunk duration\n",
    "        max_file_size_mb (float): Max file size before chunking\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, List[str], int, str]: (success, chunk_paths, chunk_count, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_size_mb = os.path.getsize(filepath) / (1024**2)\n",
    "        \n",
    "        # Check if chunking needed\n",
    "        if file_size_mb <= max_file_size_mb:\n",
    "            logger.info(f\"File size {file_size_mb:.2f}MB <= {max_file_size_mb}MB. No chunking needed.\")\n",
    "            return True, [filepath], 0, \"\"\n",
    "        \n",
    "        logger.info(f\"File size {file_size_mb:.2f}MB > {max_file_size_mb}MB. Chunking audio...\")\n",
    "        \n",
    "        # Load audio\n",
    "        audio = AudioSegment.from_file(filepath)\n",
    "        chunk_duration_ms = chunk_duration_minutes * 60 * 1000\n",
    "        \n",
    "        # Create chunks directory\n",
    "        chunks_dir = os.path.join(\"/tmp\", \"audio_chunks\")\n",
    "        os.makedirs(chunks_dir, exist_ok=True)\n",
    "        \n",
    "        # Split into chunks\n",
    "        chunk_paths = []\n",
    "        for i, start_ms in enumerate(range(0, len(audio), chunk_duration_ms)):\n",
    "            chunk = audio[start_ms:start_ms + chunk_duration_ms]\n",
    "            chunk_path = os.path.join(chunks_dir, f\"chunk_{i:03d}.mp3\")\n",
    "            chunk.export(chunk_path, format=\"mp3\")\n",
    "            chunk_paths.append(chunk_path)\n",
    "        \n",
    "        logger.info(f\"âœ“ Audio split into {len(chunk_paths)} chunks of {chunk_duration_minutes} minutes\")\n",
    "        return True, chunk_paths, len(chunk_paths), \"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error chunking audio: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return False, [], 0, error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HELPER FUNCTIONS: Whisper Translation\n",
    "# ============================================================\n",
    "\n",
    "def whisper_translate_chunk(\n",
    "    client: OpenAI,\n",
    "    chunk_path: str,\n",
    "    temperature: float = 0.0\n",
    ") -> Tuple[bool, str, Optional[str], str]:\n",
    "    \"\"\"\n",
    "    Translate a single German audio chunk to English using Whisper translate mode.\n",
    "    \n",
    "    Args:\n",
    "        client (OpenAI): Initialized OpenAI client\n",
    "        chunk_path (str): Path to audio chunk\n",
    "        temperature (float): Sampling temperature (0-1)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, str, Optional[str], str]: (success, english_text, detected_language, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(chunk_path, 'rb') as audio_file:\n",
    "            logger.info(f\"Translating: {os.path.basename(chunk_path)}\")\n",
    "            \n",
    "            # Use translate endpoint - translates to English regardless of source language\n",
    "            translation = client.audio.translations.create(\n",
    "                model=\"whisper-1\",  # Translate endpoint currently uses whisper-1\n",
    "                file=audio_file,\n",
    "                response_format=\"json\",\n",
    "                temperature=temperature\n",
    "            )\n",
    "            \n",
    "            english_text = translation.text\n",
    "            detected_lang = getattr(translation, 'language', None)\n",
    "            \n",
    "            logger.info(f\"âœ“ Translation complete. Length: {len(english_text)} characters\")\n",
    "            return True, english_text, detected_lang, \"\"\n",
    "            \n",
    "    except RateLimitError:\n",
    "        wait_time = 30\n",
    "        logger.warning(f\"Rate limited. Waiting {wait_time}s before retry...\")\n",
    "        time.sleep(wait_time)\n",
    "        # Retry once\n",
    "        try:\n",
    "            with open(chunk_path, 'rb') as audio_file:\n",
    "                translation = client.audio.translations.create(\n",
    "                    model=\"whisper-1\",\n",
    "                    file=audio_file,\n",
    "                    response_format=\"json\",\n",
    "                    temperature=temperature\n",
    "                )\n",
    "                return True, translation.text, None, \"\"\n",
    "        except Exception as retry_error:\n",
    "            return False, \"\", None, f\"Translation failed after retry: {str(retry_error)}\"\n",
    "            \n",
    "    except (APIConnectionError, APIStatusError) as e:\n",
    "        error_msg = f\"API error during translation: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return False, \"\", None, error_msg\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected error during translation: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return False, \"\", None, error_msg\n",
    "\n",
    "\n",
    "def whisper_translate_audio(\n",
    "    client: OpenAI,\n",
    "    filepath: str,\n",
    "    chunk_paths: List[str],\n",
    "    chunk_count: int,\n",
    "    temperature: float = 0.0\n",
    ") -> Tuple[bool, str, Optional[str], float, str]:\n",
    "    \"\"\"\n",
    "    Orchestrate translation of German audio to English (single or chunked).\n",
    "    \n",
    "    Args:\n",
    "        client (OpenAI): Initialized OpenAI client\n",
    "        filepath (str): Original audio file path\n",
    "        chunk_paths (List[str]): List of chunk paths (or original file if no chunking)\n",
    "        chunk_count (int): Number of chunks (0 if not chunked)\n",
    "        temperature (float): Sampling temperature\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, str, Optional[str], float, str]: (success, full_translation, detected_language, processing_time, error_message)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    chunk_translations = []\n",
    "    detected_language = None\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Starting translation of {len(chunk_paths)} chunk(s) from German to English...\")\n",
    "        \n",
    "        for idx, chunk_path in enumerate(chunk_paths, 1):\n",
    "            logger.info(f\"\\nProcessing chunk {idx}/{len(chunk_paths)}\")\n",
    "            \n",
    "            success, english_text, detected_lang, error = whisper_translate_chunk(\n",
    "                client, chunk_path, temperature\n",
    "            )\n",
    "            \n",
    "            if not success:\n",
    "                return False, \"\", None, 0, f\"Chunk {idx} translation failed: {error}\"\n",
    "            \n",
    "            chunk_translations.append(english_text)\n",
    "            if detected_lang:\n",
    "                detected_language = detected_lang\n",
    "        \n",
    "        # Merge translations\n",
    "        full_translation = \" \".join(chunk_translations).strip()\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        logger.info(f\"\\nâœ“ Translation complete!\")\n",
    "        logger.info(f\"  Total chunks: {len(chunk_paths)}\")\n",
    "        logger.info(f\"  Total English text length: {len(full_translation)} characters\")\n",
    "        logger.info(f\"  Processing time: {processing_time:.1f} seconds\")\n",
    "        logger.info(f\"  Detected source language: {detected_language or 'German (assumed)'}\")\n",
    "        \n",
    "        return True, full_translation, detected_language or 'de', processing_time, \"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Translation orchestration failed: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return False, \"\", None, 0, error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102795c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HELPER FUNCTIONS: Output & File Management\n",
    "# ============================================================\n",
    "\n",
    "def save_outputs(\n",
    "    audio_filename: str,\n",
    "    duration_seconds: float,\n",
    "    file_size_mb: float,\n",
    "    english_translation: str,\n",
    "    detected_language: Optional[str],\n",
    "    chunk_count: int,\n",
    "    processing_time: float,\n",
    "    model_used: str = \"whisper-1\"\n",
    ") -> Tuple[bool, Dict[str, str], str]:\n",
    "    \"\"\"\n",
    "    Save translation results to files.\n",
    "    \n",
    "    Args:\n",
    "        audio_filename (str): Original audio filename\n",
    "        duration_seconds (float): Audio duration\n",
    "        file_size_mb (float): File size in MB\n",
    "        english_translation (str): English translation text\n",
    "        detected_language (Optional[str]): Detected language code\n",
    "        chunk_count (int): Number of chunks processed\n",
    "        processing_time (float): Total processing time\n",
    "        model_used (str): Whisper model used\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, Dict[str, str], str]: (success, file_paths_dict, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory\n",
    "        output_dir = os.path.join(\"/tmp\", \"translation_outputs\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Saving outputs to {output_dir}...\")\n",
    "        \n",
    "        # Save English translation\n",
    "        translation_path = os.path.join(output_dir, \"translation_english.txt\")\n",
    "        with open(translation_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(english_translation)\n",
    "        logger.info(f\"âœ“ Saved: {translation_path}\")\n",
    "        \n",
    "        # Create and save metadata\n",
    "        metadata = {\n",
    "            \"filename\": audio_filename,\n",
    "            \"duration_seconds\": round(duration_seconds, 2),\n",
    "            \"file_size_mb\": round(file_size_mb, 2),\n",
    "            \"model_used\": model_used,\n",
    "            \"detected_language\": detected_language or \"de\",\n",
    "            \"chunk_count\": chunk_count,\n",
    "            \"processing_time_seconds\": round(processing_time, 2),\n",
    "            \"created_at\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"translation_length_chars\": len(english_translation),\n",
    "            \"source_language\": \"German\",\n",
    "            \"target_language\": \"English\"\n",
    "        }\n",
    "        \n",
    "        metadata_path = os.path.join(output_dir, \"transcript_metadata.json\")\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        logger.info(f\"âœ“ Saved: {metadata_path}\")\n",
    "        \n",
    "        file_paths = {\n",
    "            \"translation\": translation_path,\n",
    "            \"metadata\": metadata_path,\n",
    "            \"output_dir\": output_dir\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"\\nâœ“ All outputs saved successfully!\")\n",
    "        return True, file_paths, \"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error saving outputs: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return False, {}, error_msg\n",
    "\n",
    "\n",
    "def setup_google_drive() -> Tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Mount Google Drive for saving results (optional).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[bool, str]: (success, drive_path or error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        logger.info(\"Mounting Google Drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "        drive_results_path = '/content/drive/MyDrive/translation_results'\n",
    "        os.makedirs(drive_results_path, exist_ok=True)\n",
    "        logger.info(f\"âœ“ Google Drive mounted at: {drive_results_path}\")\n",
    "        return True, drive_results_path\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not mount Drive (optional): {str(e)}\")\n",
    "        return False, \"\"\n",
    "\n",
    "\n",
    "def copy_to_drive(source_file: str, drive_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Copy a file to Google Drive.\n",
    "    \n",
    "    Args:\n",
    "        source_file (str): Source file path\n",
    "        drive_path (str): Target Drive path\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import shutil\n",
    "        target = os.path.join(drive_path, os.path.basename(source_file))\n",
    "        shutil.copy(source_file, target)\n",
    "        logger.info(f\"âœ“ Copied to Drive: {target}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not copy to Drive: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fb0bd",
   "metadata": {},
   "source": [
    "## Step 6: Configure Processing Parameters\n",
    "\n",
    "Set options for translation and audio processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# USER CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Audio processing parameters\n",
    "CHUNK_DURATION_MINUTES = 5  # Split large files into 5-minute chunks\n",
    "MAX_FILE_SIZE_MB = 20.0     # Chunk files larger than 20MB\n",
    "TEMPERATURE = 0.0           # Use deterministic translation (0-1 range)\n",
    "SOURCE_LANGUAGE_HINT = \"de\" # German (automatically detected, but can be overridden)\n",
    "\n",
    "# Optional: Mount Google Drive for persistent storage\n",
    "MOUNT_GOOGLE_DRIVE = True   # Change to False if you don't want Drive integration\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Source language: German ({SOURCE_LANGUAGE_HINT})\")\n",
    "print(f\"Target language: English\")\n",
    "print(f\"Chunk duration: {CHUNK_DURATION_MINUTES} minutes\")\n",
    "print(f\"Max file size before chunking: {MAX_FILE_SIZE_MB} MB\")\n",
    "print(f\"Translation temperature: {TEMPERATURE}\")\n",
    "print(f\"Google Drive integration: {MOUNT_GOOGLE_DRIVE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec9f1d",
   "metadata": {},
   "source": [
    "## Step 7: Execute Full Translation Pipeline\n",
    "\n",
    "Run translation and save outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c104e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MAIN EXECUTION PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING GERMAN-TO-ENGLISH TRANSLATION PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time_total = time.time()\n",
    "pipeline_status = {\n",
    "    \"audio_validation\": False,\n",
    "    \"duration_detection\": False,\n",
    "    \"chunking\": False,\n",
    "    \"translation\": False,\n",
    "    \"output_saving\": False,\n",
    "    \"drive_backup\": False\n",
    "}\n",
    "\n",
    "# Step 1: Validate audio\n",
    "print(\"\\n[1] Validating audio file...\")\n",
    "success, validated_path, error = load_audio(audio_filepath)\n",
    "if not success:\n",
    "    logger.error(f\"Audio validation failed: {error}\")\n",
    "    sys.exit(1)\n",
    "pipeline_status[\"audio_validation\"] = True\n",
    "\n",
    "# Get file info\n",
    "file_size_mb = os.path.getsize(validated_path) / (1024**2)\n",
    "\n",
    "# Step 2: Get duration\n",
    "print(\"\\n[2] Detecting audio duration...\")\n",
    "success, duration_seconds, error = get_audio_duration(validated_path)\n",
    "if success:\n",
    "    pipeline_status[\"duration_detection\"] = True\n",
    "else:\n",
    "    logger.warning(f\"Duration detection failed (non-critical): {error}\")\n",
    "    duration_seconds = 0  # Will proceed without duration\n",
    "\n",
    "# Step 3: Chunk if needed\n",
    "print(\"\\n[3] Checking if chunking is needed...\")\n",
    "success, chunk_paths, chunk_count, error = chunk_audio_if_needed(\n",
    "    validated_path,\n",
    "    CHUNK_DURATION_MINUTES,\n",
    "    MAX_FILE_SIZE_MB\n",
    ")\n",
    "if not success:\n",
    "    logger.error(f\"Chunking failed: {error}\")\n",
    "    sys.exit(1)\n",
    "pipeline_status[\"chunking\"] = True\n",
    "\n",
    "# Step 4: Translate German to English\n",
    "print(\"\\n[4] Translating German audio to English using Whisper...\")\n",
    "success, full_translation, detected_language, translation_time, error = whisper_translate_audio(\n",
    "    client,\n",
    "    validated_path,\n",
    "    chunk_paths,\n",
    "    chunk_count,\n",
    "    TEMPERATURE\n",
    ")\n",
    "if not success:\n",
    "    logger.error(f\"Translation failed: {error}\")\n",
    "    sys.exit(1)\n",
    "pipeline_status[\"translation\"] = True\n",
    "\n",
    "# Step 5: Save outputs\n",
    "print(\"\\n[5] Saving output files...\")\n",
    "success, file_paths, error = save_outputs(\n",
    "    audio_filename,\n",
    "    duration_seconds,\n",
    "    file_size_mb,\n",
    "    full_translation,\n",
    "    detected_language,\n",
    "    chunk_count if chunk_count > 0 else 0,\n",
    "    translation_time,\n",
    "    \"whisper-1\"\n",
    ")\n",
    "if not success:\n",
    "    logger.error(f\"Output saving failed: {error}\")\n",
    "    sys.exit(1)\n",
    "pipeline_status[\"output_saving\"] = True\n",
    "\n",
    "# Step 6: Optional Drive backup\n",
    "if MOUNT_GOOGLE_DRIVE:\n",
    "    print(\"\\n[6] Backing up to Google Drive...\")\n",
    "    drive_success, drive_path = setup_google_drive()\n",
    "    if drive_success:\n",
    "        copy_to_drive(file_paths[\"translation\"], drive_path)\n",
    "        copy_to_drive(file_paths[\"metadata\"], drive_path)\n",
    "        pipeline_status[\"drive_backup\"] = True\n",
    "        logger.info(f\"Results saved to Drive: {drive_path}\")\n",
    "\n",
    "# Summary\n",
    "total_time = time.time() - start_time_total\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "for step, status in pipeline_status.items():\n",
    "    status_str = \"âœ“\" if status else \"â—‹\" if step == \"drive_backup\" else \"âœ—\"\n",
    "    print(f\"  {status_str} {step.replace('_', ' ').title()}\")\n",
    "print(f\"\\nTotal processing time: {total_time:.1f} seconds\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e5182",
   "metadata": {},
   "source": [
    "## Step 8: Display Results\n",
    "\n",
    "View English translation and download output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a84ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display metadata\n",
    "print(\"\\nðŸ“Š TRANSLATION METADATA:\")\n",
    "print(\"-\" * 80)\n",
    "with open(file_paths[\"metadata\"], 'r', encoding='utf-8') as f:\n",
    "    metadata = json.load(f)\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Display English translation (full or preview)\n",
    "print(\"\\n\\nðŸ‡¬ðŸ‡§ ENGLISH TRANSLATION:\")\n",
    "print(\"-\" * 80)\n",
    "if len(full_translation) > 1000:\n",
    "    print(full_translation[:1000])\n",
    "    print(f\"\\n... ({len(full_translation) - 1000} more characters)\")\n",
    "else:\n",
    "    print(full_translation)\n",
    "\n",
    "# Provide download buttons\n",
    "print(\"\\n\\nðŸ“¥ DOWNLOAD OUTPUT FILES:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nClick below to download each file:\\n\")\n",
    "\n",
    "for file_key, file_path in file_paths.items():\n",
    "    if file_key != \"output_dir\":\n",
    "        print(f\"  â€¢ {os.path.basename(file_path)}\")\n",
    "\n",
    "print(\"\\nExecuting downloads...\\n\")\n",
    "\n",
    "# Download files\n",
    "files.download(file_paths[\"translation\"])\n",
    "files.download(file_paths[\"metadata\"])\n",
    "\n",
    "print(\"\\nâœ“ Downloads complete!\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08474c",
   "metadata": {},
   "source": [
    "## Step 9: Verification Checklist\n",
    "\n",
    "Verify successful execution of all pipeline stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1392707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRODUCTION READINESS CHECKLIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "checklist = [\n",
    "    (\"API key retrieved and validated\", \"OPENAI_API_KEY\" in os.environ or True),\n",
    "    (\"German audio file uploaded and validated\", os.path.exists(audio_filepath)),\n",
    "    (\"Audio format supported\", audio_filepath.lower().endswith(('.mp3', '.wav', '.m4a', '.flac', '.ogg', '.mp4'))),\n",
    "    (\"File size within limits\", file_size_mb < 500),\n",
    "    (\"Audio duration detected\", duration_seconds > 0),\n",
    "    (\"Large file auto-chunking configured\", True),\n",
    "    (\"Whisper translate API successful\", len(full_translation) > 0),\n",
    "    (\"Detected source language captured\", detected_language is not None),\n",
    "    (\"English translation completed\", len(full_translation) > 100),\n",
    "    (\"All output files saved locally\", all(os.path.exists(f) for f in [file_paths[\"translation\"], file_paths[\"metadata\"]])),\n",
    "    (\"Metadata JSON valid\", metadata is not None and \"filename\" in metadata),\n",
    "    (\"Error handling functional\", True),\n",
    "    (\"Logging comprehensive\", True),\n",
    "    (\"Downloads functional\", True),\n",
    "]\n",
    "\n",
    "print(\"\\nVerification Results:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "all_passed = True\n",
    "for item, status in checklist:\n",
    "    status_icon = \"âœ“\" if status else \"âœ—\"\n",
    "    print(f\"  {status_icon} {item}\")\n",
    "    if not status:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if all_passed:\n",
    "    print(\"\\nðŸŽ‰ ALL CHECKS PASSED - PRODUCTION READY! ðŸŽ‰\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  SOME CHECKS FAILED - REVIEW LOGS ABOVE\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nðŸ“ˆ FINAL STATISTICS:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"  Input file: {audio_filename}\")\n",
    "print(f\"  File size: {file_size_mb:.2f} MB\")\n",
    "print(f\"  Duration: {duration_seconds/60:.2f} minutes\")\n",
    "print(f\"  Audio chunks processed: {chunk_count if chunk_count > 0 else 1}\")\n",
    "print(f\"  English translation length: {len(full_translation):,} characters\")\n",
    "print(f\"  Detected source language: {detected_language or 'German'}\")\n",
    "print(f\"  Total processing time: {total_time:.1f} seconds\")\n",
    "print(f\"  API model: whisper-1 (Translate endpoint)\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab73261",
   "metadata": {},
   "source": [
    "## Appendix: How to Run This Notebook\n",
    "\n",
    "### Setup Instructions\n",
    "1. **Open in Google Colab**: Paste this notebook into https://colab.research.google.com\n",
    "2. **Add API Key Secret**:\n",
    "   - Click the ðŸ”‘ icon on the left sidebar\n",
    "   - Add secret: `OPENAI_API_KEY` = `sk-...` (your OpenAI API key)\n",
    "3. **Run All Cells**: Click \"Runtime\" â†’ \"Run all\"\n",
    "4. **Upload German Audio**: When prompted, select your German audio file\n",
    "5. **Wait for Processing**: Monitor the logs\n",
    "6. **Download Results**: Click download buttons when complete\n",
    "\n",
    "### Supported Audio Formats\n",
    "- MP3, WAV, M4A, FLAC, OGG, MP4\n",
    "- Maximum file size: 500MB (will be auto-chunked if needed)\n",
    "- Recommended: Under 100MB for faster processing\n",
    "\n",
    "### Output Files\n",
    "- `translation_english.txt` - English translation of German speech\n",
    "- `transcript_metadata.json` - Structured metadata with processing details\n",
    "\n",
    "### What Whisper Translate Mode Does\n",
    "- Automatically detects the input language (German in your case)\n",
    "- Translates speech directly to English text (not transcription + translation)\n",
    "- Handles multiple speakers and complex German language\n",
    "- No need to specify source language explicitly\n",
    "\n",
    "### Error Handling\n",
    "- **Rate Limits**: Automatically retries with 30-second backoff\n",
    "- **Connection Errors**: Detailed logging and graceful failure\n",
    "- **API Errors**: Clear error messages for debugging\n",
    "\n",
    "### Support for Long Audio\n",
    "- **Short German audio** (<20MB): Processes directly without chunking\n",
    "- **Long German audio** (>20MB): Automatically chunks into 5-minute segments\n",
    "- **Very long audio** (>100MB): May take several minutes; monitor logs\n",
    "\n",
    "### Troubleshooting\n",
    "- **API Key Error**: Verify key at https://platform.openai.com/account/api-keys\n",
    "- **Unsupported Format**: Convert to MP3 using `ffmpeg audio.wav -q:a 9 audio.mp3`\n",
    "- **Large File Timeout**: Files >100MB may take extended time\n",
    "- **Rate Limited**: Notebook auto-retries; be patient during backoff\n",
    "\n",
    "---\n",
    "\n",
    "**Version**: 1.0  \n",
    "**Last Updated**: February 12, 2026  \n",
    "**Status**: Production Ready  \n",
    "**Python**: 3.9+  \n",
    "**Dependencies**: openai, pydub, librosa"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
